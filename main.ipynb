{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"gpuType":"V28","provenance":[]},"accelerator":"TPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":84895,"databundleVersionId":10008389,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"LyU3TSv8FrZ9","cell_type":"code","source":"from numba import cuda\n\ndef is_gpu_available():\n    try:\n        return cuda.is_available()\n    except:\n        return False\n\ngpu_available = is_gpu_available()\nprint(f\"GPU is available: {gpu_available}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LyU3TSv8FrZ9","outputId":"89e1efbc-26aa-4272-9c7a-21bd0fdd9c6c","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T01:11:44.804477Z","iopub.execute_input":"2025-05-19T01:11:44.804763Z","iopub.status.idle":"2025-05-19T01:11:46.908019Z","shell.execute_reply.started":"2025-05-19T01:11:44.804740Z","shell.execute_reply":"2025-05-19T01:11:46.907275Z"}},"outputs":[{"name":"stdout","text":"GPU is available: True\n","output_type":"stream"}],"execution_count":1},{"id":"7T0mas9FnnVc","cell_type":"code","source":"if gpu_available:\n    import cudf as pd\n    from cuml.preprocessing import LabelEncoder, StandardScaler\n    from cuml.model_selection import train_test_split\nelse:\n    import pandas as pd\n    from sklearn.preprocessing import LabelEncoder, StandardScaler\n    from sklearn.model_selection import train_test_split","metadata":{"id":"7T0mas9FnnVc","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T01:11:46.909482Z","iopub.execute_input":"2025-05-19T01:11:46.909780Z","iopub.status.idle":"2025-05-19T01:11:55.277286Z","shell.execute_reply.started":"2025-05-19T01:11:46.909752Z","shell.execute_reply":"2025-05-19T01:11:55.276710Z"}},"outputs":[],"execution_count":2},{"id":"yKQM5eilojGZ","cell_type":"markdown","source":"# Read Data\nuse cudf to read data into GPU\n\n- delete unuseful colums(id, Name, City)\n- Combine[(Academic Pressure, Work Pressure), (Working professional or student, Profession), (Study Satisfaction, Job Satisfaction)]\n- Normalize or mapping","metadata":{"id":"yKQM5eilojGZ"}},{"id":"QLW8I_xTorYi","cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/playground-series-s4e11/train.csv\")\n\n\n# drop 'id' , 'Name' (Not revelant), 'city'\ndf.drop(['id', 'Name'], axis=1, inplace=True)\ndf.drop(['City'], axis=1, inplace=True)\n# combine 'working professional or student' and 'Profession'\ndf['Working Professional or Student'] = df['Profession'].fillna(df['Working Professional or Student'])\ndf.drop(['Profession'], axis=1, inplace=True)\n# combine 'Academic Pressure' and 'Work Pressure'\ndf['Academic Pressure'] = df['Work Pressure'].fillna(df['Academic Pressure'])\ndf.drop(['Work Pressure'], axis=1, inplace=True)\n# combine 'Study Satisfaction' and 'Job Satisfaction'\ndf['Study Satisfaction'] = df['Job Satisfaction'].fillna(df['Study Satisfaction'])\ndf.drop(['Job Satisfaction'], axis=1, inplace=True)\n# most of 'CGPA' leave null, drop it\ndf.drop(['CGPA'], axis=1, inplace=True)\n\n# one - hot encoder\ndf['Working Professional or Student'] = LabelEncoder().fit_transform(df['Working Professional or Student'])\ndf['Degree'] = LabelEncoder().fit_transform(df['Degree'])\ndf['Academic Pressure'] = LabelEncoder().fit_transform(df['Academic Pressure'])\n\n\n# bool\ndf['Have you ever had suicidal thoughts ?'] = df['Have you ever had suicidal thoughts ?'].map({'Yes': 1, 'No': 0})\ndf['Family History of Mental Illness'] = df['Family History of Mental Illness'].map({'Yes': 1, 'No': 0})\ndf['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\ndf['Sleep Duration'] = df['Sleep Duration'].map({'Less than 5 hours': 0, '5-6 hours': 1, '7-8 hours': 2, 'More than 8 hours': 3})\ndf['Dietary Habits'] = df['Dietary Habits'].map({'Healthy': 0, 'Moderate': 1, 'Unhealthy': 2})\n\n# normalize all constant value\ncols_to_scale = [\n    'Age', 'Academic Pressure', 'Study Satisfaction',\n    'Work/Study Hours', 'Financial Stress'\n]\nscaler = StandardScaler()\ndf[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])\n\n\ndf.head(10)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":469},"id":"QLW8I_xTorYi","outputId":"1bfd87e6-bc9f-4378-81b3-a311fdf51167","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T01:11:55.278065Z","iopub.execute_input":"2025-05-19T01:11:55.278426Z","iopub.status.idle":"2025-05-19T01:12:05.106717Z","shell.execute_reply.started":"2025-05-19T01:11:55.278407Z","shell.execute_reply":"2025-05-19T01:12:05.105938Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Gender       Age  Working Professional or Student  Academic Pressure  \\\n0       0  0.695360                               10           1.407041   \n1       1 -1.161867                               55           0.693745   \n2       1 -0.596624                               54           1.407041   \n3       1 -1.484863                               55           1.407041   \n4       0 -0.838871                                9          -1.446144   \n5       0  1.502850                               26          -0.732848   \n6       1  0.533862                               11           1.407041   \n7       1 -0.192879                               55          -0.019551   \n8       0 -1.323365                               54          -0.732848   \n9       0  0.130117                               22           0.693745   \n\n   Study Satisfaction  Sleep Duration  Dietary Habits  Degree  \\\n0           -0.689253               3               0      33   \n1            0.022383               0               2      63   \n2           -0.689253               1               0      21   \n3           -1.400889               0               1      28   \n4           -1.400889               1               2      28   \n5            1.445655               1               0      82   \n6           -0.689253               2               1      83   \n7            0.734019               2               2      21   \n8            1.445655               1               1      36   \n9           -1.400889               1               0      84   \n\n   Have you ever had suicidal thoughts ?  Work/Study Hours  Financial Stress  \\\n0                                      0         -1.363057         -0.699607   \n1                                      1          0.193928          0.007793   \n2                                      1         -0.844062         -1.407006   \n3                                      1          0.972421         -1.407006   \n4                                      1          0.712923          0.715193   \n5                                      0          0.193928          1.422593   \n6                                      0         -0.065570         -0.699607   \n7                                      0          0.972421          0.007793   \n8                                      0         -0.844062         -0.699607   \n9                                      1          0.193928         -0.699607   \n\n   Family History of Mental Illness  Depression  \n0                                 0           0  \n1                                 0           1  \n2                                 0           1  \n3                                 1           1  \n4                                 1           0  \n5                                 0           0  \n6                                 0           0  \n7                                 1           0  \n8                                 1           0  \n9                                 1           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Working Professional or Student</th>\n      <th>Academic Pressure</th>\n      <th>Study Satisfaction</th>\n      <th>Sleep Duration</th>\n      <th>Dietary Habits</th>\n      <th>Degree</th>\n      <th>Have you ever had suicidal thoughts ?</th>\n      <th>Work/Study Hours</th>\n      <th>Financial Stress</th>\n      <th>Family History of Mental Illness</th>\n      <th>Depression</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.695360</td>\n      <td>10</td>\n      <td>1.407041</td>\n      <td>-0.689253</td>\n      <td>3</td>\n      <td>0</td>\n      <td>33</td>\n      <td>0</td>\n      <td>-1.363057</td>\n      <td>-0.699607</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-1.161867</td>\n      <td>55</td>\n      <td>0.693745</td>\n      <td>0.022383</td>\n      <td>0</td>\n      <td>2</td>\n      <td>63</td>\n      <td>1</td>\n      <td>0.193928</td>\n      <td>0.007793</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>-0.596624</td>\n      <td>54</td>\n      <td>1.407041</td>\n      <td>-0.689253</td>\n      <td>1</td>\n      <td>0</td>\n      <td>21</td>\n      <td>1</td>\n      <td>-0.844062</td>\n      <td>-1.407006</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>-1.484863</td>\n      <td>55</td>\n      <td>1.407041</td>\n      <td>-1.400889</td>\n      <td>0</td>\n      <td>1</td>\n      <td>28</td>\n      <td>1</td>\n      <td>0.972421</td>\n      <td>-1.407006</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>-0.838871</td>\n      <td>9</td>\n      <td>-1.446144</td>\n      <td>-1.400889</td>\n      <td>1</td>\n      <td>2</td>\n      <td>28</td>\n      <td>1</td>\n      <td>0.712923</td>\n      <td>0.715193</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>1.502850</td>\n      <td>26</td>\n      <td>-0.732848</td>\n      <td>1.445655</td>\n      <td>1</td>\n      <td>0</td>\n      <td>82</td>\n      <td>0</td>\n      <td>0.193928</td>\n      <td>1.422593</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>0.533862</td>\n      <td>11</td>\n      <td>1.407041</td>\n      <td>-0.689253</td>\n      <td>2</td>\n      <td>1</td>\n      <td>83</td>\n      <td>0</td>\n      <td>-0.065570</td>\n      <td>-0.699607</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>-0.192879</td>\n      <td>55</td>\n      <td>-0.019551</td>\n      <td>0.734019</td>\n      <td>2</td>\n      <td>2</td>\n      <td>21</td>\n      <td>0</td>\n      <td>0.972421</td>\n      <td>0.007793</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>-1.323365</td>\n      <td>54</td>\n      <td>-0.732848</td>\n      <td>1.445655</td>\n      <td>1</td>\n      <td>1</td>\n      <td>36</td>\n      <td>0</td>\n      <td>-0.844062</td>\n      <td>-0.699607</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0.130117</td>\n      <td>22</td>\n      <td>0.693745</td>\n      <td>-1.400889</td>\n      <td>1</td>\n      <td>0</td>\n      <td>84</td>\n      <td>1</td>\n      <td>0.193928</td>\n      <td>-0.699607</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"id":"B1kGNivTot3j","cell_type":"code","source":"# delete any row with null value\ndf = df.dropna()\n\nX = df.drop(columns=['Depression'])\ny = df['Depression']\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)","metadata":{"id":"B1kGNivTot3j","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T01:12:05.107633Z","iopub.execute_input":"2025-05-19T01:12:05.107869Z","iopub.status.idle":"2025-05-19T01:12:08.581119Z","shell.execute_reply.started":"2025-05-19T01:12:05.107851Z","shell.execute_reply":"2025-05-19T01:12:08.580578Z"}},"outputs":[],"execution_count":4},{"id":"Y7W0cm7oeGue","cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\ndef evaluate_model(y_true, y_pred):\n\n    def to_cpu_array(x):\n        if hasattr(x, 'to_numpy'):  # cuDF Series\n            return x.to_numpy()\n        # elif hasattr(x, 'get'):     # cupy array\n        #     return x.get()\n        # elif hasattr(x, 'cpu'):     # torch tensor\n        #     return x.cpu().numpy()\n        # elif isinstance(x, (list, np.ndarray)):\n        #     return np.array(x)\n        else:\n            return x  # fallback\n\n    y_true = to_cpu_array(y_true)\n    y_pred = to_cpu_array(y_pred)\n\n    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n    print(\"Classification Report:\\n\", classification_report(y_true, y_pred))","metadata":{"id":"Y7W0cm7oeGue","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T01:12:08.582506Z","iopub.execute_input":"2025-05-19T01:12:08.582774Z","iopub.status.idle":"2025-05-19T01:12:08.587784Z","shell.execute_reply.started":"2025-05-19T01:12:08.582746Z","shell.execute_reply":"2025-05-19T01:12:08.586915Z"}},"outputs":[],"execution_count":5},{"id":"5cw7TWwkGha4","cell_type":"markdown","source":"# Machine Learning Method","metadata":{"id":"5cw7TWwkGha4"}},{"id":"O_jrhUhgCQGe","cell_type":"code","source":"if gpu_available:\n    from cuml.linear_model import LogisticRegression\n    from cuml.ensemble  import RandomForestClassifier\n    from cuml.svm import SVC\n    from cuml.naive_bayes import GaussianNB\n    from cuml.neighbors import KNeighborsClassifier\nelse:\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.ensemble import RandomForestClassifier\n    from sklearn.svm import SVC\n    from sklearn.naive_bayes import GaussianNB\n    from sklearn.neighbors import KNeighborsClassifier\n\n# Logistic Regression\nmodel = LogisticRegression(max_iter=500)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint(\"-\" * 50 + \"Losgistic Regression\" + \"-\" * 50)\nevaluate_model(y_test, y_pred)\n\n\n# Random Forest\nmodel = RandomForestClassifier(criterion=\"log_loss\",\n                               n_estimators=120, random_state=102)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint(\"-\" * 50 + \"Random Forest\" + \"-\" * 50)\nevaluate_model(y_test, y_pred)\n\n\n# SVM\nmodel = SVC()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint(\"-\" * 50 + \"SVM\" + \"-\" * 50)\nevaluate_model(y_test, y_pred)\n\n# To-do: still debugging\n# # Naive Bayes\n# model = GaussianNB()\n# model.fit(X_train, y_train)\n# y_pred = model.predict(X_test)\n# print(\"-\" * 50 + \"Naive Bayes\" + \"-\" * 50)\n# evaluate_model(y_test, y_pred)\n\n# KNN\nmodel = KNeighborsClassifier(n_neighbors=5)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint(\"-\" * 50 + \"KNN\" + \"-\" * 50)\nevaluate_model(y_test, y_pred)\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O_jrhUhgCQGe","outputId":"bceb25b7-eec4-4d42-a3e3-1f606a8ff02f","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T01:12:08.588430Z","iopub.execute_input":"2025-05-19T01:12:08.588664Z","iopub.status.idle":"2025-05-19T01:12:16.897801Z","shell.execute_reply.started":"2025-05-19T01:12:08.588647Z","shell.execute_reply":"2025-05-19T01:12:16.897150Z"}},"outputs":[{"name":"stdout","text":"--------------------------------------------------Losgistic Regression--------------------------------------------------\nAccuracy: 0.9293159261499058\nConfusion Matrix:\n [[22176   829]\n [ 1158  3948]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.95      0.96      0.96     23005\n           1       0.83      0.77      0.80      5106\n\n    accuracy                           0.93     28111\n   macro avg       0.89      0.87      0.88     28111\nweighted avg       0.93      0.93      0.93     28111\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n  return init_func(self, *args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------Random Forest--------------------------------------------------\nAccuracy: 0.9366084450926684\nConfusion Matrix:\n [[22236   769]\n [ 1013  4093]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.96      0.97      0.96     23005\n           1       0.84      0.80      0.82      5106\n\n    accuracy                           0.94     28111\n   macro avg       0.90      0.88      0.89     28111\nweighted avg       0.94      0.94      0.94     28111\n\n--------------------------------------------------SVM--------------------------------------------------\nAccuracy: 0.9283198747821138\nConfusion Matrix:\n [[22290   715]\n [ 1300  3806]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.94      0.97      0.96     23005\n           1       0.84      0.75      0.79      5106\n\n    accuracy                           0.93     28111\n   macro avg       0.89      0.86      0.87     28111\nweighted avg       0.93      0.93      0.93     28111\n\n--------------------------------------------------KNN--------------------------------------------------\nAccuracy: 0.9215609547863826\nConfusion Matrix:\n [[22022   983]\n [ 1222  3884]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.95      0.96      0.95     23005\n           1       0.80      0.76      0.78      5106\n\n    accuracy                           0.92     28111\n   macro avg       0.87      0.86      0.87     28111\nweighted avg       0.92      0.92      0.92     28111\n\n","output_type":"stream"}],"execution_count":6},{"id":"4iXr_Ks5DsP0","cell_type":"code","source":"# XGBoost\nfrom xgboost import XGBClassifier\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\ncounter = Counter(y_train.to_numpy())\nscale = counter[0] / counter[1]\nprint(scale)\ntree_method = 'gpu_hist' if gpu_available else 'hist'\npredictor = 'gpu_predictor' if gpu_available else 'cpu_predictor'\n\nmodel = XGBClassifier(scale_pos_weight=scale * 0.4, n_estimators=150,\n    learning_rate=0.05, max_depth=20,\n    subsample=0.8, colsample_bytree=0.8,\n    eval_metric='aucpr',\n    use_label_encoder=False,\n    random_state=42,\n)\n\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint(\"-\" * 50 + \"XGBoost\" + \"-\" * 50)\nevaluate_model(y_test, y_pred)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4iXr_Ks5DsP0","outputId":"54a47d5e-05fb-4c50-cc06-67eae7a6c72b","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T01:16:53.907859Z","iopub.execute_input":"2025-05-19T01:16:53.908551Z","iopub.status.idle":"2025-05-19T01:16:57.292405Z","shell.execute_reply.started":"2025-05-19T01:16:53.908530Z","shell.execute_reply":"2025-05-19T01:16:57.291742Z"}},"outputs":[{"name":"stdout","text":"4.505679592636114\n--------------------------------------------------XGBoost--------------------------------------------------\nAccuracy: 0.9366440183558038\nConfusion Matrix:\n [[22117   888]\n [  893  4213]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.96      0.96      0.96     23005\n           1       0.83      0.83      0.83      5106\n\n    accuracy                           0.94     28111\n   macro avg       0.89      0.89      0.89     28111\nweighted avg       0.94      0.94      0.94     28111\n\n","output_type":"stream"}],"execution_count":13},{"id":"6BS4cFVAHEFY","cell_type":"markdown","source":"# Neural Network","metadata":{"id":"6BS4cFVAHEFY"}},{"id":"wFZxVE64HGOB","cell_type":"code","source":"","metadata":{"id":"wFZxVE64HGOB","trusted":true},"outputs":[],"execution_count":null}]}