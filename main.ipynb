{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"gpuType":"V28","provenance":[]},"accelerator":"TPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":84895,"databundleVersionId":10008389,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"LyU3TSv8FrZ9","cell_type":"code","source":"from numba import cuda\n\ndef is_gpu_available():\n    try:\n        return cuda.is_available()\n    except:\n        return False\n\ngpu_available = is_gpu_available()\nprint(f\"GPU is available: {gpu_available}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LyU3TSv8FrZ9","outputId":"89e1efbc-26aa-4272-9c7a-21bd0fdd9c6c","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:55:58.579699Z","iopub.execute_input":"2025-05-19T04:55:58.580009Z","iopub.status.idle":"2025-05-19T04:55:58.585216Z","shell.execute_reply.started":"2025-05-19T04:55:58.579987Z","shell.execute_reply":"2025-05-19T04:55:58.584337Z"}},"outputs":[{"name":"stdout","text":"GPU is available: True\n","output_type":"stream"}],"execution_count":19},{"id":"7T0mas9FnnVc","cell_type":"code","source":"if gpu_available:\n    import cudf as pd\n    from cuml.preprocessing import LabelEncoder, StandardScaler\n    from cuml.model_selection import train_test_split\nelse:\n    import pandas as pd\n    from sklearn.preprocessing import LabelEncoder, StandardScaler\n    from sklearn.model_selection import train_test_split","metadata":{"id":"7T0mas9FnnVc","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:55:58.586583Z","iopub.execute_input":"2025-05-19T04:55:58.586864Z","iopub.status.idle":"2025-05-19T04:55:58.601459Z","shell.execute_reply.started":"2025-05-19T04:55:58.586848Z","shell.execute_reply":"2025-05-19T04:55:58.600753Z"}},"outputs":[],"execution_count":20},{"id":"yKQM5eilojGZ","cell_type":"markdown","source":"# Read Data\nuse cudf to read data into GPU\n\n- delete unuseful colums(id, Name, City)\n- Combine[(Academic Pressure, Work Pressure), (Working professional or student, Profession), (Study Satisfaction, Job Satisfaction)]\n- Normalize or mapping","metadata":{"id":"yKQM5eilojGZ"}},{"id":"QLW8I_xTorYi","cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/playground-series-s4e11/train.csv\")\n\n\n# drop 'id' , 'Name' (Not revelant), 'city'\ndf.drop(['id', 'Name'], axis=1, inplace=True)\ndf.drop(['City'], axis=1, inplace=True)\n# combine 'working professional or student' and 'Profession'\ndf['Working Professional or Student'] = df['Profession'].fillna(df['Working Professional or Student'])\ndf.drop(['Profession'], axis=1, inplace=True)\n# combine 'Academic Pressure' and 'Work Pressure'\ndf['Academic Pressure'] = df['Work Pressure'].fillna(df['Academic Pressure'])\ndf.drop(['Work Pressure'], axis=1, inplace=True)\n# combine 'Study Satisfaction' and 'Job Satisfaction'\ndf['Study Satisfaction'] = df['Job Satisfaction'].fillna(df['Study Satisfaction'])\ndf.drop(['Job Satisfaction'], axis=1, inplace=True)\n# most of 'CGPA' leave null, drop it\ndf.drop(['CGPA'], axis=1, inplace=True)\n\n# one - hot encoder\ndf['Working Professional or Student'] = LabelEncoder().fit_transform(df['Working Professional or Student'])\ndf['Degree'] = LabelEncoder().fit_transform(df['Degree'])\ndf['Academic Pressure'] = LabelEncoder().fit_transform(df['Academic Pressure'])\n\n\n# bool\ndf['Have you ever had suicidal thoughts ?'] = df['Have you ever had suicidal thoughts ?'].map({'Yes': 1, 'No': 0})\ndf['Family History of Mental Illness'] = df['Family History of Mental Illness'].map({'Yes': 1, 'No': 0})\ndf['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\ndf['Sleep Duration'] = df['Sleep Duration'].map({'Less than 5 hours': 0, '5-6 hours': 1, '7-8 hours': 2, 'More than 8 hours': 3})\ndf['Dietary Habits'] = df['Dietary Habits'].map({'Healthy': 0, 'Moderate': 1, 'Unhealthy': 2})\n\n# normalize all constant value\ncols_to_scale = [\n    'Age', 'Academic Pressure', 'Study Satisfaction',\n    'Work/Study Hours', 'Financial Stress'\n]\nscaler = StandardScaler()\ndf[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])\n\n\ndf.head(10)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":469},"id":"QLW8I_xTorYi","outputId":"1bfd87e6-bc9f-4378-81b3-a311fdf51167","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:55:58.605832Z","iopub.execute_input":"2025-05-19T04:55:58.606072Z","iopub.status.idle":"2025-05-19T04:55:58.787748Z","shell.execute_reply.started":"2025-05-19T04:55:58.606056Z","shell.execute_reply":"2025-05-19T04:55:58.787121Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"   Gender       Age  Working Professional or Student  Academic Pressure  \\\n0       0  0.695360                               10           1.407041   \n1       1 -1.161867                               55           0.693745   \n2       1 -0.596624                               54           1.407041   \n3       1 -1.484863                               55           1.407041   \n4       0 -0.838871                                9          -1.446144   \n5       0  1.502850                               26          -0.732848   \n6       1  0.533862                               11           1.407041   \n7       1 -0.192879                               55          -0.019551   \n8       0 -1.323365                               54          -0.732848   \n9       0  0.130117                               22           0.693745   \n\n   Study Satisfaction  Sleep Duration  Dietary Habits  Degree  \\\n0           -0.689253               3               0      33   \n1            0.022383               0               2      63   \n2           -0.689253               1               0      21   \n3           -1.400889               0               1      28   \n4           -1.400889               1               2      28   \n5            1.445655               1               0      82   \n6           -0.689253               2               1      83   \n7            0.734019               2               2      21   \n8            1.445655               1               1      36   \n9           -1.400889               1               0      84   \n\n   Have you ever had suicidal thoughts ?  Work/Study Hours  Financial Stress  \\\n0                                      0         -1.363057         -0.699607   \n1                                      1          0.193928          0.007793   \n2                                      1         -0.844062         -1.407006   \n3                                      1          0.972421         -1.407006   \n4                                      1          0.712923          0.715193   \n5                                      0          0.193928          1.422593   \n6                                      0         -0.065570         -0.699607   \n7                                      0          0.972421          0.007793   \n8                                      0         -0.844062         -0.699607   \n9                                      1          0.193928         -0.699607   \n\n   Family History of Mental Illness  Depression  \n0                                 0           0  \n1                                 0           1  \n2                                 0           1  \n3                                 1           1  \n4                                 1           0  \n5                                 0           0  \n6                                 0           0  \n7                                 1           0  \n8                                 1           0  \n9                                 1           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Working Professional or Student</th>\n      <th>Academic Pressure</th>\n      <th>Study Satisfaction</th>\n      <th>Sleep Duration</th>\n      <th>Dietary Habits</th>\n      <th>Degree</th>\n      <th>Have you ever had suicidal thoughts ?</th>\n      <th>Work/Study Hours</th>\n      <th>Financial Stress</th>\n      <th>Family History of Mental Illness</th>\n      <th>Depression</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.695360</td>\n      <td>10</td>\n      <td>1.407041</td>\n      <td>-0.689253</td>\n      <td>3</td>\n      <td>0</td>\n      <td>33</td>\n      <td>0</td>\n      <td>-1.363057</td>\n      <td>-0.699607</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-1.161867</td>\n      <td>55</td>\n      <td>0.693745</td>\n      <td>0.022383</td>\n      <td>0</td>\n      <td>2</td>\n      <td>63</td>\n      <td>1</td>\n      <td>0.193928</td>\n      <td>0.007793</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>-0.596624</td>\n      <td>54</td>\n      <td>1.407041</td>\n      <td>-0.689253</td>\n      <td>1</td>\n      <td>0</td>\n      <td>21</td>\n      <td>1</td>\n      <td>-0.844062</td>\n      <td>-1.407006</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>-1.484863</td>\n      <td>55</td>\n      <td>1.407041</td>\n      <td>-1.400889</td>\n      <td>0</td>\n      <td>1</td>\n      <td>28</td>\n      <td>1</td>\n      <td>0.972421</td>\n      <td>-1.407006</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>-0.838871</td>\n      <td>9</td>\n      <td>-1.446144</td>\n      <td>-1.400889</td>\n      <td>1</td>\n      <td>2</td>\n      <td>28</td>\n      <td>1</td>\n      <td>0.712923</td>\n      <td>0.715193</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>1.502850</td>\n      <td>26</td>\n      <td>-0.732848</td>\n      <td>1.445655</td>\n      <td>1</td>\n      <td>0</td>\n      <td>82</td>\n      <td>0</td>\n      <td>0.193928</td>\n      <td>1.422593</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>0.533862</td>\n      <td>11</td>\n      <td>1.407041</td>\n      <td>-0.689253</td>\n      <td>2</td>\n      <td>1</td>\n      <td>83</td>\n      <td>0</td>\n      <td>-0.065570</td>\n      <td>-0.699607</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>-0.192879</td>\n      <td>55</td>\n      <td>-0.019551</td>\n      <td>0.734019</td>\n      <td>2</td>\n      <td>2</td>\n      <td>21</td>\n      <td>0</td>\n      <td>0.972421</td>\n      <td>0.007793</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>-1.323365</td>\n      <td>54</td>\n      <td>-0.732848</td>\n      <td>1.445655</td>\n      <td>1</td>\n      <td>1</td>\n      <td>36</td>\n      <td>0</td>\n      <td>-0.844062</td>\n      <td>-0.699607</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0.130117</td>\n      <td>22</td>\n      <td>0.693745</td>\n      <td>-1.400889</td>\n      <td>1</td>\n      <td>0</td>\n      <td>84</td>\n      <td>1</td>\n      <td>0.193928</td>\n      <td>-0.699607</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"id":"B1kGNivTot3j","cell_type":"code","source":"# delete any row with null value\ndf = df.dropna()\n\nX = df.drop(columns=['Depression'])\ny = df['Depression']\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)","metadata":{"id":"B1kGNivTot3j","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:55:58.788996Z","iopub.execute_input":"2025-05-19T04:55:58.789204Z","iopub.status.idle":"2025-05-19T04:55:58.838635Z","shell.execute_reply.started":"2025-05-19T04:55:58.789189Z","shell.execute_reply":"2025-05-19T04:55:58.838141Z"}},"outputs":[],"execution_count":22},{"id":"Y7W0cm7oeGue","cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\ndef evaluate_model(y_true, y_pred):\n\n    def to_cpu_array(x):\n        if hasattr(x, 'to_numpy'):  # cuDF Series\n            return x.to_numpy()\n        # elif hasattr(x, 'get'):     # cupy array\n        #     return x.get()\n        # elif hasattr(x, 'cpu'):     # torch tensor\n        #     return x.cpu().numpy()\n        # elif isinstance(x, (list, np.ndarray)):\n        #     return np.array(x)\n        else:\n            return x  # fallback\n\n    y_true = to_cpu_array(y_true)\n    y_pred = to_cpu_array(y_pred)\n\n    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n    print(\"Classification Report:\\n\", classification_report(y_true, y_pred))","metadata":{"id":"Y7W0cm7oeGue","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:55:58.839253Z","iopub.execute_input":"2025-05-19T04:55:58.839415Z","iopub.status.idle":"2025-05-19T04:55:58.844222Z","shell.execute_reply.started":"2025-05-19T04:55:58.839403Z","shell.execute_reply":"2025-05-19T04:55:58.843547Z"}},"outputs":[],"execution_count":23},{"id":"5cw7TWwkGha4","cell_type":"markdown","source":"# Machine Learning Method","metadata":{"id":"5cw7TWwkGha4"}},{"id":"O_jrhUhgCQGe","cell_type":"code","source":"if gpu_available:\n    from cuml.linear_model import LogisticRegression\n    from cuml.ensemble  import RandomForestClassifier\n    from cuml.svm import SVC\n    from cuml.naive_bayes import GaussianNB\n    from cuml.neighbors import KNeighborsClassifier\nelse:\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.ensemble import RandomForestClassifier\n    from sklearn.svm import SVC\n    from sklearn.naive_bayes import GaussianNB\n    from sklearn.neighbors import KNeighborsClassifier\n\n# Logistic Regression\nmodel = LogisticRegression(max_iter=500)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint(\"-\" * 50 + \"Losgistic Regression\" + \"-\" * 50)\nevaluate_model(y_test, y_pred)\n\n\n# Random Forest\nmodel = RandomForestClassifier(criterion=\"log_loss\",\n                               n_estimators=120, random_state=102)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint(\"-\" * 50 + \"Random Forest\" + \"-\" * 50)\nevaluate_model(y_test, y_pred)\n\n\n# SVM\nmodel = SVC()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint(\"-\" * 50 + \"SVM\" + \"-\" * 50)\nevaluate_model(y_test, y_pred)\n\n# To-do: still debugging\n# # Naive Bayes\n# model = GaussianNB()\n# model.fit(X_train, y_train)\n# y_pred = model.predict(X_test)\n# print(\"-\" * 50 + \"Naive Bayes\" + \"-\" * 50)\n# evaluate_model(y_test, y_pred)\n\n# KNN\nmodel = KNeighborsClassifier(n_neighbors=5)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint(\"-\" * 50 + \"KNN\" + \"-\" * 50)\nevaluate_model(y_test, y_pred)\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O_jrhUhgCQGe","outputId":"bceb25b7-eec4-4d42-a3e3-1f606a8ff02f","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:55:58.845885Z","iopub.execute_input":"2025-05-19T04:55:58.846061Z","iopub.status.idle":"2025-05-19T04:56:03.950420Z","shell.execute_reply.started":"2025-05-19T04:55:58.846048Z","shell.execute_reply":"2025-05-19T04:56:03.949708Z"}},"outputs":[{"name":"stdout","text":"--------------------------------------------------Losgistic Regression--------------------------------------------------\nAccuracy: 0.9292803528867704\nConfusion Matrix:\n [[22177   828]\n [ 1160  3946]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.95      0.96      0.96     23005\n           1       0.83      0.77      0.80      5106\n\n    accuracy                           0.93     28111\n   macro avg       0.89      0.87      0.88     28111\nweighted avg       0.93      0.93      0.93     28111\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n  return init_func(self, *args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------Random Forest--------------------------------------------------\nAccuracy: 0.9366084450926684\nConfusion Matrix:\n [[22236   769]\n [ 1013  4093]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.96      0.97      0.96     23005\n           1       0.84      0.80      0.82      5106\n\n    accuracy                           0.94     28111\n   macro avg       0.90      0.88      0.89     28111\nweighted avg       0.94      0.94      0.94     28111\n\n--------------------------------------------------SVM--------------------------------------------------\nAccuracy: 0.9283198747821138\nConfusion Matrix:\n [[22290   715]\n [ 1300  3806]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.94      0.97      0.96     23005\n           1       0.84      0.75      0.79      5106\n\n    accuracy                           0.93     28111\n   macro avg       0.89      0.86      0.87     28111\nweighted avg       0.93      0.93      0.93     28111\n\n--------------------------------------------------KNN--------------------------------------------------\nAccuracy: 0.9215609547863826\nConfusion Matrix:\n [[22022   983]\n [ 1222  3884]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.95      0.96      0.95     23005\n           1       0.80      0.76      0.78      5106\n\n    accuracy                           0.92     28111\n   macro avg       0.87      0.86      0.87     28111\nweighted avg       0.92      0.92      0.92     28111\n\n","output_type":"stream"}],"execution_count":24},{"id":"4iXr_Ks5DsP0","cell_type":"code","source":"# XGBoost\nfrom xgboost import XGBClassifier\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\ncounter = Counter(y_train.to_numpy())\nscale = counter[0] / counter[1]\nprint(scale)\ntree_method = 'gpu_hist' if gpu_available else 'hist'\npredictor = 'gpu_predictor' if gpu_available else 'cpu_predictor'\n\nmodel = XGBClassifier(scale_pos_weight=scale * 0.4, n_estimators=150,\n    learning_rate=0.05, max_depth=20,\n    subsample=0.8, colsample_bytree=0.8,\n    eval_metric='aucpr',\n    use_label_encoder=False,\n    random_state=42,\n)\n\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint(\"-\" * 50 + \"XGBoost\" + \"-\" * 50)\nevaluate_model(y_test, y_pred)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4iXr_Ks5DsP0","outputId":"54a47d5e-05fb-4c50-cc06-67eae7a6c72b","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:56:03.951069Z","iopub.execute_input":"2025-05-19T04:56:03.951342Z","iopub.status.idle":"2025-05-19T04:56:07.536452Z","shell.execute_reply.started":"2025-05-19T04:56:03.951323Z","shell.execute_reply":"2025-05-19T04:56:07.535788Z"}},"outputs":[{"name":"stdout","text":"4.505679592636114\n--------------------------------------------------XGBoost--------------------------------------------------\nAccuracy: 0.9366440183558038\nConfusion Matrix:\n [[22117   888]\n [  893  4213]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.96      0.96      0.96     23005\n           1       0.83      0.83      0.83      5106\n\n    accuracy                           0.94     28111\n   macro avg       0.89      0.89      0.89     28111\nweighted avg       0.94      0.94      0.94     28111\n\n","output_type":"stream"}],"execution_count":25},{"id":"6BS4cFVAHEFY","cell_type":"markdown","source":"# Neural Network","metadata":{"id":"6BS4cFVAHEFY"}},{"id":"35f86018-75ae-4bb1-ac25-c719c1a7c616","cell_type":"code","source":"import torch\nfrom torch.utils import dlpack\nimport cudf\n\ndef cudf_to_torch(df: cudf.DataFrame) ->torch.Tensor:\n    dlpack_capsule = df.astype(\"float32\").to_dlpack() \n    return torch_dlpack.from_dlpack(dlpack_capsule)\n    \nX_train = cudf_to_torch(X_train)\nX_test = cudf_to_torch(X_test)\ny_train = cudf_to_torch(y_train)\ny_test = cudf_to_torch(y_test)\n\nfrom torch.utils.data import TensorDataset, DataLoader\n\ntrain_ds = TensorDataset(X_train, y_train)\ntest_ds  = TensorDataset(X_test,  y_test)\n\nbatch_size = 256\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\ntest_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:56:07.537108Z","iopub.execute_input":"2025-05-19T04:56:07.537286Z","iopub.status.idle":"2025-05-19T04:56:07.549641Z","shell.execute_reply.started":"2025-05-19T04:56:07.537273Z","shell.execute_reply":"2025-05-19T04:56:07.548971Z"}},"outputs":[],"execution_count":26},{"id":"wFZxVE64HGOB","cell_type":"code","source":"# MLP\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchmetrics\nfrom tqdm import tqdm\n\nclass MLP(nn.Module):\n    def __init__(self, in_features, hidden=[256, 128, 64], dropout=0.3):\n        super().__init__()\n        layers = []\n        dim = in_features\n        for h in hidden:\n            layers += [nn.Linear(dim, h), nn.ReLU(), nn.Dropout(dropout)] # Linear → ReLU → Dropout\n            dim = h\n        layers.append(nn.Linear(dim, 1)) # Output logic 1 dim         \n        self.net = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.net(x).squeeze(1)\n\n\ndevice = torch.device(\"cuda\") if gpu_available else torch.device(\"cpu\")\nmodel  = MLP(X_train.shape[1]).to(device)\n\n# pos_weight = N_neg / N_pos\npos_weight = torch.tensor(\n    (y_train == 0).sum() / (y_train == 1).sum(),\n    dtype=torch.float32, device=device\n)\ncriterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode=\"min\", factor=0.5, patience=3, verbose=True\n)\n\nbest_loss, best_state = float(\"inf\") , None\nepochs = 10\nfor epoch in range(1, epochs + 1):\n    # --- train ---\n    model.train()\n    running_loss = 0.0\n    for xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch}\", leave=False):      \n        optimizer.zero_grad(set_to_none=True)\n        loss = criterion(model(xb), yb)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * xb.size(0)\n\n    epoch_loss = running_loss / len(train_loader.dataset)\n    print(f\"[Epoch {epoch}] train_loss = {epoch_loss:.4f}\")\n    scheduler.step(epoch_loss)\n\n    if epoch_loss < best_loss:\n        best_loss, best_state = epoch_loss, model.state_dict()\n\nmodel.load_state_dict(best_state)\nmodel.eval()\nwith torch.no_grad():\n    y_prob = torch.sigmoid(torch.cat([model(xb) for xb, _ in test_loader])).cpu().numpy()\n\n# --- 3.1 计算最优阈值 (最大 F1) ---\nfrom sklearn.metrics import precision_recall_curve, classification_report\nprec, rec, thr = precision_recall_curve(y_test.cpu().numpy(), y_prob)\nf1   = 2 * prec * rec / (prec + rec + 1e-9)\nbest_thr = thr[f1.argmax()]\nprint(f\"best_thr = {best_thr:.4f},  best F1 = {f1.max():.4f}\")\n\ny_pred = (y_prob >= best_thr).astype(int)\nevaluate_model(y_test.cpu().numpy(), y_pred)","metadata":{"id":"wFZxVE64HGOB","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:59:54.558307Z","iopub.execute_input":"2025-05-19T04:59:54.558960Z","iopub.status.idle":"2025-05-19T05:00:12.901071Z","shell.execute_reply.started":"2025-05-19T04:59:54.558936Z","shell.execute_reply":"2025-05-19T05:00:12.900464Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/1434294181.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  pos_weight = torch.tensor(\n                                                           \r","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] train_loss = 0.7059\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"[Epoch 2] train_loss = 0.4406\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"[Epoch 3] train_loss = 0.4089\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"[Epoch 4] train_loss = 0.3989\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"[Epoch 5] train_loss = 0.3918\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"[Epoch 6] train_loss = 0.3873\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"[Epoch 7] train_loss = 0.3846\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"[Epoch 8] train_loss = 0.3841\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"[Epoch 9] train_loss = 0.3820\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"[Epoch 10] train_loss = 0.3802\nbest_thr = 0.7494,  best F1 = 0.8134\nAccuracy: 0.9292447796236348\nConfusion Matrix:\n [[21788  1217]\n [  772  4334]]\nClassification Report:\n               precision    recall  f1-score   support\n\n         0.0       0.97      0.95      0.96     23005\n         1.0       0.78      0.85      0.81      5106\n\n    accuracy                           0.93     28111\n   macro avg       0.87      0.90      0.88     28111\nweighted avg       0.93      0.93      0.93     28111\n\n","output_type":"stream"}],"execution_count":30},{"id":"2f5b1976-2868-444f-a683-8256c63e039f","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}